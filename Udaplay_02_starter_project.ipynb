{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# [STARTER] Udaplay Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "a963d4ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T00:27:14.883318Z",
     "start_time": "2025-07-24T00:27:14.878882Z"
    }
   },
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "fd10c06e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T00:27:14.940265Z",
     "start_time": "2025-07-24T00:27:14.936432Z"
    }
   },
   "source": [
    "# TODO: Import the necessary libs\n",
    "# For example: \n",
    "# import os\n",
    "\n",
    "# from lib.agents import Agent\n",
    "# from lib.llm import LLM\n",
    "# from lib.messages import UserMessage, SystemMessage, ToolMessage, AIMessage\n",
    "# from lib.tooling import tool\n",
    "import os\n",
    "import json\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from tavily import TavilyClient\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "87e465d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T00:27:15.040047Z",
     "start_time": "2025-07-24T00:27:14.991934Z"
    }
   },
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Validate required API keys with helpful error messages\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\n",
    "        'OPENAI_API_KEY not found in environment variables. '\n",
    "        'Please create a .env file with OPENAI_API_KEY=\"your_key\"'\n",
    "    )\n",
    "\n",
    "tavily_api_key = os.getenv('TAVILY_API_KEY')\n",
    "if not tavily_api_key:\n",
    "    raise ValueError(\n",
    "        'TAVILY_API_KEY not found in environment variables. '\n",
    "        'Please create a .env file with TAVILY_API_KEY=\"your_key\"'\n",
    "    )\n",
    "\n",
    "# Initialize clients with error handling\n",
    "try:\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://openai.vocareum.com/v1\",\n",
    "        api_key=openai_api_key,\n",
    "    )\n",
    "except Exception as e:\n",
    "    raise ValueError(f'Failed to initialize OpenAI client: {str(e)}')\n",
    "\n",
    "try:\n",
    "    tavily_client = TavilyClient(api_key=tavily_api_key)\n",
    "except Exception as e:\n",
    "    raise ValueError(f'Failed to initialize Tavily client: {str(e)}')\n",
    "\n",
    "print('âœ… API clients initialized successfully!')"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "ce364221",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T00:27:15.063238Z",
     "start_time": "2025-07-24T00:27:15.058331Z"
    }
   },
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "class AgentAnswer(BaseModel):\n",
    "    answer: str = Field(description=\"The direct answer to the user's question.\")\n",
    "    source: str = Field(description=\"The source of the information, either the game's name or 'Web Search'.\")\n",
    "    fallback_used: bool = Field(description=\"True if a web search was required to answer the question.\")\n",
    "    internal_reasoning: str = Field(description=\"The agent's step-by-step reasoning for its conclusion.\")\n"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "id": "b25c36dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T00:27:15.169696Z",
     "start_time": "2025-07-24T00:27:15.164188Z"
    }
   },
   "source": [
    "# TODO: Create retrieve_game tool\n",
    "# It should use chroma client and collection you created\n",
    "# chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "# collection = chroma_client.get_collection(\"udaplay\")\n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - query: a question about game industry. \n",
    "#\n",
    "#    You'll receive results as list. Each element contains:\n",
    "#    - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "#    - Name: Name of the Game\n",
    "#    - YearOfRelease: Year when that game was released for that platform\n",
    "#    - Description: Additional details about the game\n",
    "\n",
    "#  --- Tool 1: RAG Retrieval ---\n",
    "def retrieve_game_info(query: str, n_results: int = 3) -> list[str]:\n",
    "    \"\"\"\n",
    "    Queries the ChromaDB vector store to find relevant game information.\n",
    "    \"\"\"\n",
    "    print(f\"Tool: Retrieving game info for query: '{query}'\")\n",
    "    chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "\n",
    "    embedding_fn = embedding_functions.OpenAIEmbeddingFunction(\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        api_base=\"https://openai.vocareum.com/v1\",  # For Vocareum\n",
    "        model_name=\"text-embedding-ada-002\"\n",
    "    )\n",
    "\n",
    "    collection = chroma_client.get_collection(\n",
    "        name=\"udaplay\",\n",
    "        embedding_function=embedding_fn\n",
    "    )\n",
    "\n",
    "    # --- This part was missing ---\n",
    "    results = collection.query(query_texts=[query], n_results=n_results)\n",
    "\n",
    "    # Format the retrieved documents for the next step\n",
    "    retrieved_docs = []\n",
    "    if results and results['metadatas'][0]:\n",
    "        for meta in results['metadatas'][0]:\n",
    "            # Pass the full JSON metadata as a string\n",
    "            retrieved_docs.append(json.dumps(meta))\n",
    "\n",
    "    return retrieved_docs\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "id": "0d9d014b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T00:27:15.223650Z",
     "start_time": "2025-07-24T00:27:15.217044Z"
    }
   },
   "source": [
    "# TODO: Create evaluate_retrieval tool\n",
    "# You might use an LLM as judge in this tool to evaluate the performance\n",
    "# You need to prompt that LLM with something like:\n",
    "# \"Your task is to evaluate if the documents are enough to respond the query. \"\n",
    "# \"Give a detailed explanation, so it's possible to take an action to accept it or not.\"\n",
    "# Use EvaluationReport to parse the result\n",
    "# Tool Docstring:\n",
    "#    Based on the user's question and on the list of retrieved documents, \n",
    "#    it will analyze the usability of the documents to respond to that question. \n",
    "#    args: \n",
    "#    - question: original question from user\n",
    "#    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "#    The result includes:\n",
    "#    - useful: whether the documents are useful to answer the question\n",
    "#    - description: description about the evaluation result\n",
    "def evaluate_retrieval(query: str, context: list[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Uses an LLM to decide if the retrieved context is sufficient to answer the query.\n",
    "    \"\"\"\n",
    "    # ... (rest of the function is the same) ...\n",
    "\n",
    "    # A simple but effective prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    Based *only* on the provided context below, can you confidently answer the following user question?\n",
    "    Respond with only \"yes\" or \"no\".\n",
    "\n",
    "    User Question: \"{query}\"\n",
    "\n",
    "    Context:\n",
    "    ---\n",
    "    {context}\n",
    "    ---\n",
    "    \"\"\"\n",
    "\n",
    "    # Use the configured client object here\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=5,\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "    decision = response.choices[0].message.content.strip().lower()\n",
    "    print(f\"Evaluation: LLM decision is '{decision}'.\")\n",
    "    return \"yes\" in decision\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "id": "2ad698aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T00:27:15.274816Z",
     "start_time": "2025-07-24T00:27:15.270033Z"
    }
   },
   "source": [
    "# TODO: Create game_web_search tool\n",
    "# Please use Tavily client to search the web\n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - question: a question about game industry.\n",
    "def game_web_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs a web search using Tavily if the local DB is insufficient.\n",
    "    \"\"\"\n",
    "    print(f\"Tool: Performing web search for query: '{query}'\")\n",
    "    try:\n",
    "        response = tavily_client.search(query=query, search_depth=\"basic\")\n",
    "        # We'll return the most relevant search result content\n",
    "        return response['results'][0]['content']\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Tavily search: {e}\")\n",
    "        return \"Web search failed.\""
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "id": "31c56281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T00:27:15.333773Z",
     "start_time": "2025-07-24T00:27:15.324076Z"
    }
   },
   "source": [
    "# TODO: Create your Agent abstraction using StateMachine\n",
    "# Equip with an appropriate model\n",
    "# Craft a good set of instructions \n",
    "# Plug all Tools you developed\n",
    "# %%\n",
    "# In Udaplay_02_starter_project.ipynb\n",
    "\n",
    "def run_udaplay_agent(user_query: str) -> AgentAnswer:\n",
    "    \"\"\"\n",
    "    Runs the full agent workflow for a given user query.\n",
    "    \"\"\"\n",
    "    reasoning = []\n",
    "\n",
    "    # Step 1: Retrieve information from our local RAG pipeline\n",
    "    retrieved_context = retrieve_game_info(user_query)\n",
    "    reasoning.append(\n",
    "        f\"1. Searched local database for '{user_query}'. Found {len(retrieved_context)} potential matches.\")\n",
    "\n",
    "    # Step 2: Evaluate the retrieved information\n",
    "    is_sufficient = evaluate_retrieval(user_query, retrieved_context)\n",
    "    reasoning.append(f\"2. Evaluated retrieved context. Decision: {'Sufficient' if is_sufficient else 'Insufficient'}.\")\n",
    "\n",
    "    final_context = \"\"\n",
    "    source = \"\"\n",
    "    fallback_used = False\n",
    "\n",
    "    # Step 3: Decide whether to use the retrieved context or fall back to a web search\n",
    "    if is_sufficient:\n",
    "        # Use the local data\n",
    "        final_context = \"\\n\".join(retrieved_context)\n",
    "        # For simplicity, we'll cite the first game found as the source\n",
    "        source_game = json.loads(retrieved_context[0])\n",
    "        source = source_game.get(\"Name\", \"Local Database\")\n",
    "        reasoning.append(\"3. Proceeding with information from local database.\")\n",
    "    else:\n",
    "        # Fallback to web search\n",
    "        fallback_used = True\n",
    "        web_context = game_web_search(user_query)\n",
    "        final_context = web_context\n",
    "        source = \"Web Search (Tavily)\"\n",
    "        reasoning.append(\"3. Local data was insufficient. Performing a web search.\")\n",
    "        reasoning.append(\"4. Web search provided new context.\")\n",
    "\n",
    "    # Step 4: Generate the final answer using the chosen context\n",
    "    reasoning.append(\"5. Generating final answer based on the chosen context.\")\n",
    "\n",
    "    final_prompt = f\"\"\"\n",
    "    You are the UdaPlay AI assistant. Your task is to answer the user's question based on the provided context.\n",
    "    Be concise and direct in your answer.\n",
    "\n",
    "    User Question: \"{user_query}\"\n",
    "\n",
    "    Context to use:\n",
    "    ---\n",
    "    {final_context}\n",
    "    ---\n",
    "    \"\"\"\n",
    "\n",
    "    final_response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        messages=[{\"role\": \"user\", \"content\": final_prompt}]\n",
    "    )\n",
    "\n",
    "    answer = final_response.choices[0].message.content\n",
    "\n",
    "    return AgentAnswer(\n",
    "        answer=answer,\n",
    "        source=source,\n",
    "        fallback_used=fallback_used,\n",
    "        internal_reasoning=\"\\n\".join(reasoning)\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "0ec23893",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T00:27:43.035900Z",
     "start_time": "2025-07-24T00:27:15.382689Z"
    }
   },
   "source": [
    "# TODO: Invoke your agent\n",
    "# - When PokÃ©mon Gold and Silver was released?\n",
    "# - Which one was the first 3D platformer Mario game?\n",
    "# - Was Mortal Kombat X realeased for Playstation 5?\n",
    "\n",
    "# --- Test Query 1: Answer should be in the local DB ---\n",
    "query1 = \"When was God of War Ragnarok released?\"\n",
    "answer1 = run_udaplay_agent(query1)\n",
    "print(json.dumps(answer1.model_dump(), indent=2))\n",
    "\n",
    "# --- Test Query 2: Answer requires a web search ---\n",
    "query2 = \"What is Rockstar Games working on now?\"\n",
    "answer2 = run_udaplay_agent(query2)\n",
    "print(json.dumps(answer2.model_dump(), indent=2))\n",
    "\n",
    "# --- Test Query 3: Answer should be in the local DB ---\n",
    "query3 = \"What platform was PokÃ©mon Red launched on?\"\n",
    "answer3 = run_udaplay_agent(query3)\n",
    "print(json.dumps(answer3.model_dump(), indent=2))\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: Retrieving game info for query: 'When was God of War Ragnarok released?'\n",
      "Evaluation: LLM decision is 'no'.\n",
      "Tool: Performing web search for query: 'When was God of War Ragnarok released?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"God of War Ragnarok was released on November 9, 2022, on PS5 and PS4.\",\n",
      "  \"source\": \"Web Search (Tavily)\",\n",
      "  \"fallback_used\": true,\n",
      "  \"internal_reasoning\": \"1. Searched local database for 'When was God of War Ragnarok released?'. Found 3 potential matches.\\n2. Evaluated retrieved context. Decision: Insufficient.\\n3. Local data was insufficient. Performing a web search.\\n4. Web search provided new context.\\n5. Generating final answer based on the chosen context.\"\n",
      "}\n",
      "Tool: Retrieving game info for query: 'What is Rockstar Games working on now?'\n",
      "Evaluation: LLM decision is 'no'.\n",
      "Tool: Performing web search for query: 'What is Rockstar Games working on now?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"Rockstar Games is working on \\\"Strange Tales of the West.\\\"\",\n",
      "  \"source\": \"Web Search (Tavily)\",\n",
      "  \"fallback_used\": true,\n",
      "  \"internal_reasoning\": \"1. Searched local database for 'What is Rockstar Games working on now?'. Found 3 potential matches.\\n2. Evaluated retrieved context. Decision: Insufficient.\\n3. Local data was insufficient. Performing a web search.\\n4. Web search provided new context.\\n5. Generating final answer based on the chosen context.\"\n",
      "}\n",
      "Tool: Retrieving game info for query: 'What platform was PokÃ©mon Red launched on?'\n",
      "Evaluation: LLM decision is 'no'.\n",
      "Tool: Performing web search for query: 'What platform was PokÃ©mon Red launched on?'\n",
      "{\n",
      "  \"answer\": \"Pok\\u00e9mon Red was launched on the Game Boy platform.\",\n",
      "  \"source\": \"Web Search (Tavily)\",\n",
      "  \"fallback_used\": true,\n",
      "  \"internal_reasoning\": \"1. Searched local database for 'What platform was Pok\\u00e9mon Red launched on?'. Found 3 potential matches.\\n2. Evaluated retrieved context. Decision: Insufficient.\\n3. Local data was insufficient. Performing a web search.\\n4. Web search provided new context.\\n5. Generating final answer based on the chosen context.\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### (Optional) Advanced"
   ]
  },
  {
   "cell_type": "code",
   "id": "eb83fbb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T00:27:43.061525Z",
     "start_time": "2025-07-24T00:27:43.058085Z"
    }
   },
   "source": [
    "# TODO: Update your agent with long-term memory\n",
    "# TODO: Convert the agent to be a state machine, with the tools being pre-defined nodes"
   ],
   "outputs": [],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0 (main, Dec  3 2024, 02:24:14) [GCC 10.2.1 20210110]"
  },
  "vscode": {
   "interpreter": {
    "hash": "23393d2575091a37cff0d0e9e7479591a295495b26c3b2ebf9b64da572e02d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
